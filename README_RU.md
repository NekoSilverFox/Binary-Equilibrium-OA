 <p align="center"><b><font size=5>Алгоритм оптимизации бинарного равновесия для задач 0-1 рюкзака</font></b></p>
 <p align="center"><b>A Binary Equilibrium Optimization Algorithm for 0–1 Knapsack Problems</b></p>

> <div class="author-group" id="author-group"><span class="sr-only">Author links open overlay panel</span><a class="author size-m workspace-trigger" name="bau005" href="#!"><span class="content"><span class="text given-name">Mohamed</span><span class="text surname">Abdel-Basset</span><span class="author-ref" id="baf005"><sup>a</sup></span><svg role="img" focusable="false" viewBox="0 0 102 128" width="19.125" height="24" class="icon icon-envelope" aria-label="Envelope"><title>Envelope</title><path d="m55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0l-31.32-23.2h69.54l-31.32 23.19zm-55.8-24.78l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-0.98 9.42-2.93l40.24-30.7v-10.34h-102zm92 56.48l-18.06-22.74-8.04 5.95 17.38 21.89h-64.54l18.38-23.12-8.04-5.96-19.08 24.02v-37.58l-1e1 -8.46v61.1h102v-59.18l-1e1 8.46v35.62"></path></svg></span></a><a class="author size-m workspace-trigger" name="bau010" href="#!"><span class="content"><span class="text given-name">Reda</span><span class="text surname">Mohamed</span><span class="author-ref" id="baf005"><sup>a</sup></span><svg role="img" focusable="false" viewBox="0 0 102 128" width="19.125" height="24" class="icon icon-envelope" aria-label="Envelope"><title>Envelope</title><path d="m55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0l-31.32-23.2h69.54l-31.32 23.19zm-55.8-24.78l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-0.98 9.42-2.93l40.24-30.7v-10.34h-102zm92 56.48l-18.06-22.74-8.04 5.95 17.38 21.89h-64.54l18.38-23.12-8.04-5.96-19.08 24.02v-37.58l-1e1 -8.46v61.1h102v-59.18l-1e1 8.46v35.62"></path></svg></span></a><a class="author size-m workspace-trigger" name="bau015" href="#!"><span class="content"><span class="text given-name">Seyedali</span><span class="text surname">Mirjalili</span><span class="author-ref" id="baf010"><sup>b</sup></span><span class="author-ref" id="baf015"><sup>c</sup></span><span class="author-ref" id="baf020"><sup>d</sup></span><svg role="img" focusable="false" viewBox="0 0 106 128" width="19.875" height="24" class="icon icon-person" aria-label="Person"><title>Person</title><path d="m11.07 1.2e2l0.84-9.29c1.97-18.79 23.34-22.93 41.09-22.93 17.74 0 39.11 4.13 41.08 22.84l0.84 9.38h10.04l-0.93-10.34c-2.15-20.43-20.14-31.66-51.03-31.66s-48.89 11.22-51.05 31.73l-0.91 10.27h10.03m41.93-102.29c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98s18.24-10.31 18.24-23.98c0-9.9-8.52-18.59-18.24-18.59zm0 52.29c-15.96 0-28-14.48-28-33.67 0-15.36 12.82-28.33 28-28.33s28 12.97 28 28.33c0 19.19-12.04 33.67-28 33.67"></path></svg><span class="author-ref" id="bfn1"><sup>1</sup></span><svg role="img" focusable="false" viewBox="0 0 102 128" width="19.125" height="24" class="icon icon-envelope" aria-label="Envelope"><title>Envelope</title><path d="m55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0l-31.32-23.2h69.54l-31.32 23.19zm-55.8-24.78l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-0.98 9.42-2.93l40.24-30.7v-10.34h-102zm92 56.48l-18.06-22.74-8.04 5.95 17.38 21.89h-64.54l18.38-23.12-8.04-5.96-19.08 24.02v-37.58l-1e1 -8.46v61.1h102v-59.18l-1e1 8.46v35.62"></path></svg></span></a><dl class="affiliation"><dt><sup>a</sup></dt><dd>Faculty of Computers and Informatics, Zagazig University, Zagazig 44519, Egypt</dd></dl><dl class="affiliation"><dt><sup>b</sup></dt><dd>Center for Artificial Intelligence Research and Optimization, Torrens University Australia, Australia</dd></dl><dl class="affiliation"><dt><sup>c</sup></dt><dd>Yonsei Frontier Lab, Yonsei University, Seoul, Korea</dd></dl><dl class="affiliation"><dt><sup>d</sup></dt><dd>King Abdul Aziz University, Jeddah, Saudi Arabia</dd></dl></div>
>
> https://doi.org/10.1016/j.cie.2020.106946



**Аннотация**
В данной работе предлагается бинарная версия равновесной оптимизации (BEO - binary version of equilibrium optimization) для решения задачи 0-1 ранца, которая характеризуется как дискретная задача. Поскольку стандартный оптимизатор равновесия (EO - equilibrium optimizer) был предложен для решения непрерывных задач оптимизации, для решения бинарных задач требуется дискретный вариант. Поэтому для преобразования непрерывного EO в бинарный EO (BEO) используются восемь передаточных функций, включая V-образные и S-образные. Среди этих передаточных функций в данном исследовании показано, что V-образная V3 является наилучшей. Также замечено, что сигмоидная передаточная функция S3 может быть более полезной, чем V3, для улучшения работы других алгоритмов, используемых в данной работе. Мы пришли к выводу, что производительность любого двоичного алгоритма зависит от правильного выбора передаточной функции. Кроме того, мы используем штрафную функцию для отсеивания невыполнимых решений от решений задачи и применяем алгоритм восстановления (RA) для преобразования их в выполнимые решения. Производительность предложенного алгоритма оценивается на трех эталонных наборах данных с 63 экземплярами малого, среднего и крупного масштаба и сравнивается с рядом других алгоритмов, предложенных для решения 0-1 knapsack, при различных статистических анализах. Результаты экспериментов показывают, что алгоритм BEOV3 превосходит все мелко- и среднемасштабные тестовые примеры. Что касается крупномасштабных тестовых примеров, то предложенный метод достигает оптимального значения для 13 из 18 примеров.[^2]



**Ключевые слова**
0-1 ранцевая задача; Равновесный оптимизатор; Передаточная функция; Алгоритм Бинарная оптимизация; Оптимизация роя частиц; Комбинаторная оптимизация; Искусственный интеллект; Бенчмарк

---



[toc]



# Введение

Рюкзачные задачи (РЗ) приобретают свою значимость благодаря появлению во многих реальных приложениях. Эти проблемы часто встречаются в принятии инвестиционных решений (Rooderkerk and van Heerde, 2016), проблеме погрузки груза (Mladenović, 2019, Cho, 2019, Brandt and Nickel, 2019), минимизации энергии (Müller, 2015, Karaboghossian and Zito, 2018), распределении ресурсов (Jacko, 2016), компьютерной памяти (Oppong, 2019), выборе портфеля проектов (Koc, 2009, Bas, 2012, Tavana, 2015, Tavana et al., 2013), адаптивные мультимедийные системы (Khan, 2002), криптография (Khan, 2002, Liu et al., 2019), жилищная проблема (Chan, 2018) и проблема раскроя запасов (Alfares and Alsawafy, 2019). Поэтому решение КП позволяет многим приложениям процветать и развиваться. Однако КП является NP-трудной задачей, поэтому найти решение за полиномиальное время довольно сложно. КП - это комбинаторная задача оптимизации, в которой мы стремимся найти оптимальное решение среди конечного множества решений. Если размер КП увеличивается, то время, затрачиваемое точными методами на поиск оптимального решения, растет экспоненциально. Точные методы, такие как исчерпывающий поиск или метод ветвей и границ, потребляют огромные вычислительные ресурсы в пространстве и времени, особенно для крупномасштабных КП. Следовательно, необходимость поиска близкого к оптимальному решения за приемлемое время - это тенденция, которой следуют многие исследователи при решении КП.

В 0-1 КП, предположим, дан набор из n предметов, каждый из которых имеет частный вес $w_i$ и прибыль $p_i$. Из заданных n предметов лицам, принимающим решения, необходимо найти подмножество, которое максимизирует прибыль и при этом сумма их весов меньше или равна вместимости ранца. Чтобы найти такое подмножество товаров, был создан ранец, который содержит выбранный $i-й$ товар со значением $x_i = 1$, в то время как остальные товары имеют значение $x_i = 0$, которые не выбираются в ранец. Наконец, математически эта задача может быть сформулирована как:

$$
\operatorname{maximize} \sum_{i=1}^{n} x_{i}^{*} p_{i}

\\

subjectto \sum_{i=1}^{n} w_{i}^{*} x_{i}<c

\\

x_{i}=0 \ or \ 1, i=0,1 \cdots \cdots n

\\

p_{i}>0,\ w_{i}>0,\ c>0
$$
В последнее время предлагается множество метаэвристических алгоритмов для поиска оптимальных решений различных задач оптимизации с относительно хорошими результатами (Bairathi and Gopalani, 2018, Mirjalili and Lewis, 2016, Askarzadeh, 2016, Abualigah, 2019, Abualigah et al., 2018, Abualigah et al., 2018, Mohammad Abualigah, 2020, Abualigah and Diabat, 2020, Safaldin et al., 2020). В отличие от точных методов, метаэвристика характеризуется более быстрой сходимостью к оптимальному решению и снижением вычислительных затрат. Поэтому многие авторы пытались решить КП с помощью метаэвристики. Основной целью любой метаэвристики является эффективное исследование пространства поиска для нахождения близких к оптимальным решений. Надежный метаэвристический алгоритм - это алгоритм, который может поддерживать баланс между фазами исследования и эксплуатации. Некоторые метаэвристические алгоритмы, предложенные для решения задачи 0-1 knapsack, обсуждаются в следующем разделе.

Превосходство метаэвристических алгоритмов побудило нас предложить бинарную версию нового метаэвристического алгоритма, а именно равновесного оптимизатора (EO) (Faramarzi, 2019), вдохновленного физикой, для решения проблемы ранца. Высокая способность этого алгоритма решать непрерывную задачу послужила причиной для предложения бинарной версии, чтобы исследовать его производительность при решении задачи 0-1 ранца, характеризующейся как комбинаторная задача оптимизации. Преимущества данного алгоритма по сравнению с существующими алгоритмами сводятся к следующему:

1. Избежание преждевременной сходимости к локальному оптимуму
2. Высокая способность сохранять разнообразие популяции до конца итерации.
3. Наличие двух факторов помогает алгоритму сбалансировать способность к исследованию и эксплуатации.
4. Использование архива для сохранения четырех лучших решений, что дает алгоритму дополнительную возможность избежать застревания в локальных минимумах и впоследствии ускорить сходимость к оптимальному решению.

В соответствии с этими преимуществами, он считается сильным алгоритмом, и впоследствии исследование его производительности на дискретной задаче является необходимой командой. Для преобразования непрерывных значений EO в дискретные были использованы восемь передаточных функций, а именно V-образная и S-образная, и были проведены обширные эксперименты с этими функциями, чтобы получить наилучшую производительность с двоичной версией EO (BEO). После экспериментов стало очевидно, что V-образная функция V3 является лучшей. Кроме того, чтобы проверить эффективность BEO, он был проверен на трех эталонных наборах данных - мелко-, средне- и крупномасштабных - и сравнен с 14 современными алгоритмами. После проверки и сравнения превосходство предложенного алгоритма на большинстве экземпляров трех эталонов, особенно на крупномасштабных, стало очевидным. В заключение, основной вклад данной работы заключается в следующем:

- Предложение бинарной версии нового EO для решения задачи 0-1 ранца.
- Добавление модели принятия решений, обладающей большей способностью решать крупномасштабные ранцевые задачи, для нахождения наименее распространенной моды на срез сырья, выбора инвестиций и портфелей, генерации ключей Меркла-Хеллмана (Lagarias, 1984) и решения других ранцевых задач (Kellerer et al., 2004).
- Предположение о том, что хороший выбор передаточной функции может улучшить производительность бинарного алгоритма.

Остальные разделы данной работы организованы следующим образом. В разделе 2 рассматриваются некоторые из предыдущих работ, предложенных для решения как одиночных 0-1 КП, так и МКП. В разделе 3 кратко описывается оригинальная равновесная оптимизация. В разделе 4 мы иллюстрируем адаптацию EO для решения задачи 0-1 ранца с использованием адекватной передаточной функции в качестве предлагаемого подхода. В разделе 5 представлено обсуждение и экспериментальные результаты предложенного подхода для решения задачи 0-1 knapsack на трех наборах стандартных известных эталонов, проиллюстрированных в деталях. В разделе 6 представлены некоторые выводы по предложенному подходу и дальнейшая работа.



# Обзор литературы
Чтобы показать современное состояние дел, мы представим некоторые предыдущие работы, выполненные для решения одиночного 0-1 КП. В работе Ye et al. (Ye, 2019) для решения КП использовалась система tissue P, имитирующая механизмы биологических тканей. Хотя эта система показывает правильные результаты, авторы не проверяли ее работу на крупномасштабных КП. Ву и др. (Wu et al., 2018) объединили алгоритм симбиотического поиска с поиском гармонии для решения мелких и крупномасштабных КП.

Кроме того, Гао и др. (Gao, 2018) повысили производительность алгоритма "волчья стая" за счет использования квантового кодирования. Алгоритм использовал квантовое вращение и квантовый коллапс, чтобы перейти к глобальному поиску и избежать локального оптимума. В работе (Zouache et al., 2016); Zouache et al. интегрировали квантовую концепцию с алгоритмом светлячка и оптимизацией роя частиц, и результаты оказались весьма обнадеживающими. Другие алгоритмы, такие как гармонический осциллятор и социальная эволюция (Pavithr, 2016, Huang, 2019, Wang, 2007), используют преимущества квантовых вычислений. Метод кодирования с комплексным значением включен в алгоритм оптимизации с движением ветра (Zhou, 2017) в дополнение к жадной стратегии для увеличения разнообразия популяции и улучшения локального поиска алгоритма. Также метод комплексно-значного кодирования добавлен в алгоритм летучей мыши, чтобы разнообразить популяцию летучих мышей (Zhou et al., 2016).

В работе (Kulkarni and Shabir, 2016) алгоритм когортного интеллекта (CI) был использован для решения КП 0-1 с количеством элементов от 4 до 75. Более того, увеличение размера задачи влияет на производительность алгоритма за счет увеличения времени вычислений и оценок функций, а выбранные для экспериментов наборы данных являются низкоразмерными. Следовательно, Сапре и др. (Sapre, 2019) улучшили производительность алгоритма CI для низкоразмерных наборов данных с помощью образованного подхода, который выбирает оптимальное решение кандидата. Фенг и др. (Feng, 2018) улучшили качество решений, применив стратегию обучения на основе оппозиции (OBL) и гауссово возмущение к Monarch Butterfly Optimization (MBO). Алгоритм использовал OBL на поздней стадии на половине популяции, но стратегия гауссова возмущения работает на половине особей с минимальной приспособленностью. После этого, используя тот же алгоритм (MBO), Feng et al. (2018) применили карту хаоса для улучшения возможностей глобальной оптимизации алгоритма MBO.

Zhou et al. (2016) улучшили алгоритм обезьяны, который использует жадный алгоритм для исправления неосуществимости решений и повышения осуществимости этих решений. Более того, алгоритм повторно инициализирует популяцию, если глобальное оптимальное решение не изменилось в течение предопределенного числа итераций. Эксперименты показывают, что алгоритм может быть полезен при решении 0-1 КП. Упрощенный бинарный поиск гармонии, представленный в (Kong, 2015), зависит от разницы между гармониями, хранящимися в памяти гармоний, а не от параметров. Кроме того, El-Shafei et al. (2018) использовали параллельную обработку ускорителя Harare на базе FPGA для решения КП большой размерности с помощью двоичного поиска гармонии.

Более того, для решения задачи 0-1 ранца был разработан новый алгоритм глобального гармоничного поиска (NGHS) (Zou, 2011). NGHS был улучшен с помощью двух операций: первая - обновление позиции, которая используется для быстрого обновления наихудшей гармонии к наилучшей глобальной в течение каждой итерации, а вторая - генетическая мутация, которая стремится вывести NGHS из локального оптимума. NGHS по-прежнему страдает от застревания в локальных минимумах и впоследствии не может достичь лучших решений при решении 0-1 КП. Кроме того, был предложен улучшенный алгоритм оптимизации кита (IWOA) (Abdel-Basset et al., 2019) для решения как одиночного 0-1 КП, так и МКП. IWOA был интегрирован со стратегией локального поиска (LSS) и стратегией левитирующего полета, чтобы обеспечить лучший компромисс между операторами исследования и эксплуатации. Кроме того, IWOA была интегрирована с побитовым оператором в попытке повысить эффективность. WOA использовалась и в других бинарных задачах.

В работе (Wu, 2020) недавно был предложен дискретный гибридный алгоритм оптимизации на основе обучения (HTLBO) для решения дисконтированного КП 0-1. Оптимизационные возможности HTLBO улучшены на основе трех перспектив: (1) для повышения способности к исследованию HTLBO была улучшена стратегия обучения, (2) для баланса между операторами исследования и эксплуатации фазы учителя и ученика интегрированы с факторами самообучения, (3) наконец, два типа кроссовера были использованы для повышения поисковой способности HTLBO.



# Равновесный оптимизатор
Недавно Faramarzi (2019) предложил новый метаэвристический алгоритм, основанный на физике, под названием "оптимизатор равновесия" (EO) для решения задач непрерывной оптимизации. EO стремится найти равновесное состояние, при котором достигается баланс массы, входящей, генерируемой и выходящей из контрольного объема. Математически EO формулируется следующим образом:
$$
Step 1: initialization
$$
На этапе инициализации генерируется набор из $N$ частиц с числом размеров $n$ для каждой частицы. Размеры внутри каждой частицы инициализируются случайным образом следующим образом:
$$
\vec{v}_{i}=L_{\min }+\left(U_{\max }-\mathrm{L}_{\min }\right) * \mathrm{ri}=0,1,2, \cdots, \mathrm{N}
$$
где 𝑣⃗𝑖  - вектор, содержащий концентрации частиці, 𝐿𝑚𝑖𝑛,𝑈𝑚𝑎𝑥 - максимальная и минимальная границы пространства поиска, специализированного для каждого измерения. 𝑟 - число, генерируемое случайным образом в пределах 0 и 1.
$$
{Step 2: Equilibrium\ pool\ and\ candidates \left(c_{e q}\right)}
$$
EO работает над поиском состояния, которое достигает равновесия на
контрольном объеме. Когда EO достигает этого состояния, он может достичь близкого к оптимальному решения, которое он ищет. Как и все метаэвристические алгоритмы, в начале процесса оптимизации глобальное оптимальное решение неизвестно, поэтому они выбирают наиболее подходящее решение из популяции в качестве глобального. Аналогично, EO, в начале, не знает концентраций массы, которые могли бы достичь равновесия системы, поэтому он добавляет лучшие четыре частицы в $\overrightarrow{\mathrm{p}}_{\text {eq,pool }}$ в качестве кандидатов на равновесие в дополнение к еще одной, содержащей среднее значение лучших четырех частиц. Первые четыре кандидата на достижение равновесия в $\overrightarrow{\mathrm{p}}_{\text {eq,pool }}$ работают на повышение способности EO к исследованию, в то время как последний улучшает способность к эксплуатации.
$$
\vec{p}_{\text {eqppool }}=\left[\vec{p}_{\text {eq(1) }}, \vec{p}_{\text {eq(2) }}, \vec{p}_{\text {eq(3) }}, \vec{p}_{\text {eq(4) }}, \vec{p}_{\text {eq(avg) }}\right]
$$

$$
{Step 3: updating\ the\ concentration}
$$

Следующее уравнение было разработано для того, чтобы обеспечить правдоподобный баланс между оператором разведки и оператором эксплуатации.
$$
\vec{F}=e^{-\vec{\lambda}\left(t-t_{0}\right)}
$$


где $\vec{\lambda}$ - вектор, сгенерированный случайным образом в диапазоне (Rooderkerk and van Heerde, 2016), а $t$  постепенно уменьшается с итерациями и формулируется следующим образом:
$$
t=\left(1-\frac{i t}{t_{\max }}\right)^{(a 2^{*}\left(\frac{i t}{t_{\max }}\right)}
$$
где $it$ - текущая итерация, $t_{max }$ - максимальное количество итераций, $a 2$  - фиксированное значение, контролирующее способность ЭО к эксплуатации. В качестве еще одной попытки улучшить возможности исследования и эксплуатации EO, EO также рассматривает:
$$
\vec{t}_{0}=\frac{1}{\vec{\lambda}} \ln \left(-a_{1} \operatorname{sign}(\vec{r}-0.5)\left[1-e^{-\vec{\lambda}^{t}}\right)+t\right.
$$
где $a_{1}$ - фиксированное значение, предопределенное для управления возможностью диверсификации. В случае, если $a_{1}$  больше, то оператор разведки выше, а эксплуатации меньше. Напротив, если $a_{2}$  больше, то эксплуатационные возможности ЭО доминируют над разведочными возможностями.

Уравнение (6) описывает пересмотренный вариант уравнения (3) с заменой уравнения (5) на уравнение (3):
$$
\vec{F}=a_{1} \operatorname{sign}(\vec{r}-0.5)\left[e^{-\vec{\lambda}(t)}-1\right]
$$
Где $\vec{r}$ - случайный вектор, созданный между 0 и 1. Другой фактор $R$ был предложен для улучшения эксплуатационных возможностей EO и выглядит следующим образом:
$$
\vec{R}=\vec{R}_{0} * e^{-\vec{\lambda}^{*}\left(t-t_{0}\right)}
$$
где $R_0$ является начальным значением и рассчитывается по следующему уравнению:
$$
\vec{R}_{0}=\overrightarrow{R C P^{*}} *\left(\overrightarrow{c_{e q}}-\vec{\lambda} * \vec{C}\right)

\\

\overrightarrow{R C P}=\left\{\begin{array}{c}0.5 r_{1} r_{2}>R P \\ \text { 0 otherwise }\end{array}\right.
$$
где $r_1$  и $r_2$ - числа, генерируемые случайным образом в пределах 0 и 1. В уравнении 9 RCP используется для определения того, применяется ли $\vec{R}_{0}$ к обновленному решению или нет. $\vec{R}_{0}$ применяется, если вероятность RP меньше $r_2$, в противном случае он не применяется. Каждое решение в процессе оптимизации обычно обновляется с помощью следующего уравнения:
$$
\vec{C}=\overrightarrow{c_{e q}}+\left(\vec{C}-\overrightarrow{c_{e q}}\right) * \vec{F}+\frac{\vec{R}}{\vec{\lambda} * V} *(1-\vec{F})
$$
где $V = 1$. В целом, основные шаги EO показаны в Алгоритме 1

***Алгоритм 1 - Алгоритм EO:***

<img src="doc/pic/README/image-20221003193402394.png" alt="image-20221003193402394" style="zoom:67%;" />

# Предлагаемый подход[^2]

В этом разделе алгоритм равновесной оптимизации перерабатывается в бинарную версию для решения задач с ранцами 0-1. Стандартный EO предназначен для решения непрерывной задачи оптимизации, а задача о ранце считается дискретной задачей, поэтому он должен быть переработан, чтобы быть адекватным для решения этой задачи. Для преобразования стандартного EO в двоичную версию используется одна из передаточных функций, показанных далее, в которой непрерывное значение возвращается из стандартного алгоритма и преобразуется в 0 или 1. 0′ указывает на предмет, взятый из ранца, а значение 1′ указывает на предмет, выбранный в ранце. В следующих подразделах показаны этапы построения предлагаемого нами алгоритма.

## Инициализация

На этом этапе предлагается группа, состоящая из числа частиц 𝑁, где каждая частица содержит $n$ измерений, которые инициализируются случайным образом с реальными значениями $P_{j}$ , $ \mathrm{j}=0,1,2 \cdots n$ между 0 и 1, затем 𝑉𝑗 преобразуется в 0 или 1 на основе уравнения (11). Представление исходной группы, используемой при решении задачи 0-1 Knapsack, показано на рис. 1.
$$
P_{j}=\left\{\begin{array}{l}\text { 1 \ if } \ {P_j}>0.5 \\ \text { 0 \ otherwise }\end{array}\right.
$$
***Рис. 1. Представление исходной группы:***

<img src="doc/pic/README/Fig. 1. Representation of the initial group.jpg" alt="Fig. 1. Representation of the initial group" style="zoom:150%;" />

## Фитнес-функция
Фитнес-функция является незаменимой функцией во всех метаэвристических алгоритмах. Поэтому для решения ранцевых задач с помощью метаэвристики Равновесная оптимизация, фитнес-функция должна быть задана до тех пор, пока она не позволит найти поисковое ядро процесса оптимизации. Функция пригодности, используемая в EO для решения задачи о ранце 0-1, вычисляется как сумма прибылей предметов, найденных в ранце: $\mathrm{f}(x)=\sum_{i=1}^{n} P_{i}{ }^{*} p_{i}$ и ее результаты при условии достижения ограничения $\sum_{i=1}^{n} w_{i}{ }^{*} P_{i}<c$ , где 𝑤𝑖 ,и 𝑃𝑖 - вес и статус, 0, или 1, каждого предмета в ранце, а $c$ - вместимость ранца. Решение, которое не подчиняется предыдущему ограничению и может быть выбрано в качестве наилучшего в результате его максимальной пригодности, называется неосуществимым решением. Мы будем иметь дело с этим невыполнимым решением, используя штрафную функцию, которая дает отрицательное значение пригодности для этого решения до тех пор, пока оно не будет выбрано в качестве наилучшего. Алгоритм 2 описывает шаги штрафной функции (PF).

***Алгоритм 2. (Штрафная функция (ШФ)):***

<img src="doc/pic/README/image-20221003224219562.png" alt="image-20221003224219562" style="zoom:67%;" />

## Фиксация неосуществимого решения
В этих подразделах показаны алгоритмы, используемые для преобразования неосуществимого решения в осуществимое. На этом этапе используются два алгоритма, первый из которых, а именно алгоритм ремонта (RA), работает над исправлением неосуществимого решения, полученного от алгоритма PF, а второй, а именно алгоритм улучшения (IA), работает над улучшением осуществимого решения, полученного от RA. Эти два алгоритма перечислены ниже:

В алгоритме ремонта:
1. Из ранца удаляется элемент с наименьшим $\frac{\mathrm{p}_{i}}{\mathrm{w}_{i}}$ отношением.

2. Оценивается новое решение.

3. Проверяется выполнимость нового решения, если оно не выполнимо, то повторяются шаги 1 и 2, пока не будет найдено выполнимое решение (см. Алгоритм 3).

***Алгоритм 3 Алгоритм восстановления (RA):***

<img src="doc/pic/README/image-20221004112338611.png" alt="image-20221004112338611" style="zoom:67%;" />

В алгоритме улучшения:
1. В ранце выбирается элемент с наибольшим $\frac{\mathrm{p}_{i}}{\mathrm{w}_{i}}$ соотношением.

2. Оценивается новое решение.

3. Проверяется выполнимость нового решения, если оно не выполнимо, то удаляются последние элементы, выбранные в ранце, и процесс улучшения завершается (иллюстрация в алгоритме 4).

***Алгоритм 4 Алгоритм улучшения (IA):***

![image-20221004112857303](doc/pic/README/image-20221004112857303.png)

## Передаточные функции
Существует восемь различных передаточных функций, которые делятся на два класса: S-образные и V-образные. Они позволяют преобразовывать непрерывные значения в 0 или 1. Эти передаточные функции принимают на вход реальное значение, затем каждая из них использует определенную формулу для преобразования реального значения в значение между 0 и 1. После этого значение, находящееся между 0 и 1, преобразуется в двоичное значение с помощью уравнения (12). Формула каждой функции приведена в таблице 1, а рис. 2 иллюстрирует графическую форму той же функции. Более подробную информацию об этих передаточных функциях можно найти в (Mirjalili & Lewis, 2013). Следует отметить, что в литературе существуют бинарные варианты ЭО с одной передаточной функцией (Kushal et al., 2020, Yuanyuan et al., 2020, Zheng-Ming et al., 2020). Однако данная работа является полупопыткой интегрировать восемь передаточных функций в алгоритм BEO и тщательно сравнить их.

